# 存储

### emptyDir 类型的 Volume

```yaml
cat <<EOF | sudo tee emptydir-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: emptydir-pod
spec:
  containers:
    - name: nginx
      imagePullPolicy: IfNotPresent
      image: nginx
      ports:
        - containerPort: 80
      volumeMounts:
        - mountPath: /share-dir
          name: emptydir-volume
    - name: php-fpm
      imagePullPolicy: IfNotPresent
      image: php:7.4-fpm
      ports:
        - containerPort: 9000
      volumeMounts:
        - mountPath: /share-dir
          name: emptydir-volume
  volumes:
    - name: emptydir-volume
      emptyDir:
        { }
EOF

kubectl apply -f emptydir-pod.yaml 
```

```shell

kubectl exec emptydir-pod -c php-fpm -- touch /share-dir/a.txt
kubectl exec emptydir-pod -c nginx -- ls /share-dir
```

### hostPath 类型的 Volume

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: hostpath-pod
spec:
  containers:
    - name: nginx
      imagePullPolicy: IfNotPresent
      image: nginx
      volumeMounts:
        - mountPath: /share-dir
          name: v2
  volumes:
    - name: v2
      hostPath:
        path: /data
```

### nfs

增加一台虚拟机 `nfs(192.168.205.20)` 作为 NFS 服务器

[How To Set Up an NFS Mount on Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-18-04)

Server 端：

> 提示：在虚拟机：`nfs` 中执行命令。

```shell
sudo apt-get update
sudo apt-get install -y nfs-kernel-server
sudo systemctl start nfs-server
sudo systemctl enable nfs-server
sudo mkdir /share
cat <<EOF | sudo tee -a /etc/exports
/share    *(rw,async,no_root_squash,no_subtree_check)
EOF
sudo exportfs -arv
```

Client 端：

> 提示：在虚拟机：`k8s-2` 和 `k8s-3` 中执行命令。

```shell
sudo apt-get install -y nfs-common
showmount -e 192.168.205.20
```

返回：

```shell
Export list for 192.168.205.20:
/share *
```

```shell
sudo mkdir /share
sudo mount 192.168.205.20:/share /share
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nfs-pod
spec:
  containers:
    - name: nginx
      image: nginx
      imagePullPolicy: IfNotPresent
      volumeMounts:
        - mountPath: /share
          name: v3
  volumes:
    - name: v3
      nfs:
        path: /share
        server: 192.168.205.20
```

局限性：没有"命名空间"，数据之间没有隔离，不安全。 类型的 Volume

### persistentVolume

[一文读懂 K8s 持久化存储流程](https://developer.aliyun.com/article/754434)

|概念|缩写|含义|创建者|资源级别|
|---|---|---|---|---|
|PersistentVolume|pv|持久卷|管理员|集群|
|PersistentVolumeClaim|pvc|持久卷申领|开发者|命名空间|
|StorageClass|sc|存储类|管理员|集群|

> 提示：在虚拟机：`nfs` 中执行命令。

```shell
sudo mkdir /share2
cat <<EOF | sudo tee -a /etc/exports
/share2    *(rw,async,no_root_squash,no_subtree_check)
EOF
sudo exportfs -arv
```

创建 pv:

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv1
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: slow
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /share2
    server: 192.168.205.20
```

```shell
kubectl get pv
```

```shell
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
pv1    5Gi        RWO            Retain           Available           slow                    5s
```

创建 pvc

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc1
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 8Gi
  storageClassName: slow
```

```shell
kubectl get pvc
```

```shell
NAME   STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc1   Bound    pv1      5Gi        RWO            slow           15s
```

```shell
kubectl get pv
```

```shell
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM          STORAGECLASS   REASON   AGE
pv1    5Gi        RWO            Retain           Bound    default/pvc1   slow                    12m
```

没有指定pv name，那么 pvc1 是如何自动绑定 pv1 的？

* pvc.resources.requests.storage 与 pv.capacity.storage 存储空间匹配(<=)
* pvc.accessModes pv.accessModes 匹配(=)

精准匹配

* pvc.storageClassName 与 pv.storageClassName 匹配(=)

storageClass 的两个用途：

* 用于 pv 和 pvc 的 name 匹配(bound)
* 用于动态卷供应（dynamicProvisioning）

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pvc-pod
spec:
  containers:
    - name: nginx
      imagePullPolicy: IfNotPresent
      image: nginx
      volumeMounts:
        - mountPath: /share2
          name: v4
  volumes:
    - name: v4
      persistentVolumeClaim:
        claimName: pvc1
```

### dynamicProvisioning

作用：自动创建pv。 开发者创建pvc的时候，基于 storageClass 的分配器（provisioner）自动创建 pv，并与 pvc 绑定。

nfs 实现动态卷供应

> 提示：在虚拟机：`nfs` 中执行命令。

```shell
sudo mkdir /share3
cat <<EOF | sudo tee -a /etc/exports
/share3    *(rw,async,no_root_squash,no_subtree_check)
EOF
sudo exportfs -arv
```

> 提示：在虚拟机：`k8s-1` 中执行命令。

Kubernetes v1.20 (opens new window)开始，默认删除了 metadata.selfLink 字段，然而，部分应用仍然依赖于这个字段，例如
nfs-client-provisioner。如果仍然要继续使用这些应用，您将需要重新启用该字段。

http://www.mydlq.club/article/109/

```shell
sudo vi /etc/kubernetes/manifests/kube-apiserver.yaml

- --feature-gates=RemoveSelfLink=false

sudo systemctl restart kubelet # 等待1分钟


git clone https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner.git
cd nfs-subdir-external-provisioner

NS=$(kubectl config get-contexts|grep -e "^\*" |awk '{print $5}')
NAMESPACE=${NS:-default}
sed -i'' "s/namespace:.*/namespace: $NAMESPACE/g" ./deploy/rbac.yaml ./deploy/deployment.yaml
kubectl create -f ./deploy/rbac.yaml
kubectl apply -f ./deploy/deployment.yaml
kubectl apply -f ./deploy/class.yaml
```

```yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pvc2
spec:
  storageClassName: managed-nfs-storage
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Mi
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: dynamic-provisioning-pod
spec:
  containers:
    - name: nginx
      image: nginx
      imagePullPolicy: IfNotPresent
      volumeMounts:
        - mountPath: /share3
          name: v5
  volumes:
    - name: v5
      persistentVolumeClaim:
        claimName: pvc2
```





